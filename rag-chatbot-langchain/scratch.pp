import os
import logging
from typing import Dict, List, Optional
from dotenv import load_dotenv
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_community.vectorstores import Chroma
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain.schema import Document

# Configura√ß√£o de logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Configura√ß√µes do sistema
CONFIG = {
    "embedding_model": "models/embedding-001",
    "llm_model": "gemini-1.5-pro",
    "temperature": 0.7,
    "persist_directory": "./chroma_db",
    "max_results": 3,
    "max_retries": 3,
    "timeout": 30
}

class RAGChatbot:
    """Sistema RAG (Retrieval-Augmented Generation) para consultas sobre documenta√ß√£o."""

    def __init__(self, config: Dict = None):
        """
        Inicializa o chatbot RAG.

        Args:
            config: Dicion√°rio com configura√ß√µes personalizadas
        """
        self.config = config or CONFIG
        self.embeddings = None
        self.vectorstore = None
        self.retriever = None
        self.llm = None
        self.qa_chain = None

        self._setup_environment()
        self._initialize_components()

    def _setup_environment(self):
        """Configura as vari√°veis de ambiente e valida√ß√µes."""
        try:
            load_dotenv()
            self.google_api_key = os.getenv("GOOGLE_API_KEY")

            if not self.google_api_key:
                logger.error("A vari√°vel de ambiente GOOGLE_API_KEY n√£o est√° configurada.")
                raise ValueError("A vari√°vel de ambiente GOOGLE_API_KEY n√£o est√° configurada.")

            logger.info("Vari√°veis de ambiente carregadas com sucesso.")

        except FileNotFoundError:
            logger.error("O arquivo .env n√£o foi encontrado. Por favor, crie-o com a chave API do Google.")
            raise
        except Exception as e:
            logger.error(f"Erro ao configurar ambiente: {e}")
            raise

    def _initialize_components(self):
        """Inicializa todos os componentes do sistema RAG."""
        try:
            # Inicializa o modelo de embedding
            logger.info("Inicializando modelo de embedding...")
            self.embeddings = GoogleGenerativeAIEmbeddings(
                model=self.config["embedding_model"],
                google_api_key=self.google_api_key
            )

            # Carrega o ChromaDB persistido
            logger.info("Carregando banco de dados vetorial ChromaDB...")
            self.vectorstore = Chroma(
                persist_directory=self.config["persist_directory"],
                embedding_function=self.embeddings
            )

            # Configura o retriever com par√¢metros otimizados
            self.retriever = self.vectorstore.as_retriever(
                search_kwargs={"k": self.config["max_results"]}
            )

            # Inicializa o LLM do Google Gemini
            logger.info("Inicializando modelo de linguagem...")
            self.llm = ChatGoogleGenerativeAI(
                model=self.config["llm_model"],
                google_api_key=self.google_api_key,
                temperature=self.config["temperature"]
            )

            # Cria a cadeia RAG
            self._create_qa_chain()

            logger.info("Sistema RAG inicializado com sucesso!")

        except Exception as e:
            logger.error(f"Erro ao inicializar componentes: {e}")
            raise

    def _create_qa_chain(self):
        """Cria a cadeia de perguntas e respostas com prompt otimizado."""

        prompt_template = """Voc√™ √© um assistente especializado em documenta√ß√£o da LangChain. Use EXCLUSIVAMENTE as informa√ß√µes de contexto fornecidas para responder √† pergunta.

INSTRU√á√ïES IMPORTANTES:
- Se voc√™ n√£o souber a resposta baseada no contexto, diga: "N√£o tenho informa√ß√µes suficientes no contexto fornecido para responder a esta pergunta."
- Seja conciso e direto em suas respostas
- Cite exemplos espec√≠ficos quando dispon√≠veis no contexto
- Mantenha um tom profissional e prestativo

Contexto: {context}

Pergunta: {question}

Resposta baseada no contexto:"""

        PROMPT = PromptTemplate(
            template=prompt_template,
            input_variables=["context", "question"]
        )

        self.qa_chain = RetrievalQA.from_chain_type(
            llm=self.llm,
            chain_type="stuff",
            retriever=self.retriever,
            return_source_documents=True,
            chain_type_kwargs={"prompt": PROMPT}
        )

    def ask_question(self, query: str) -> Dict:
        """
        Processa uma pergunta e retorna a resposta com metadados.

        Args:
            query: Pergunta a ser respondida

        Returns:
            Dict com resposta, fontes e metadados
        """
        if not query or not query.strip():
            return {
                "error": "Pergunta n√£o pode estar vazia",
                "result": None,
                "source_documents": []
            }

        try:
            logger.info(f"Processando pergunta: {query}")

            # Executa a consulta
            result = self.qa_chain.invoke({"query": query})

            # Processa os documentos fonte
            sources = []
            for doc in result.get("source_documents", []):
                source_info = {
                    "source": doc.metadata.get("source", "Fonte n√£o dispon√≠vel"),
                    "page": doc.metadata.get("page", "N/A"),
                    "content_preview": doc.page_content[:200] + "..." if len(doc.page_content) > 200 else doc.page_content
                }
                sources.append(source_info)

            response_data = {
                "query": query,
                "result": result.get("result", "Resposta n√£o dispon√≠vel"),
                "source_documents": sources,
                "num_sources": len(sources)
            }

            logger.info(f"Pergunta processada com sucesso. Fontes encontradas: {len(sources)}")
            return response_data

        except Exception as e:
            logger.error(f"Erro ao processar pergunta '{query}': {e}")
            return {
                "error": f"Erro ao processar pergunta: {str(e)}",
                "result": None,
                "source_documents": []
            }

    def display_response(self, response_data: Dict):
        """Exibe a resposta de forma formatada."""
        if response_data.get("error"):
            print(f"‚ùå Erro: {response_data['error']}")
            return

        print(f"\nü§ñ Pergunta: {response_data['query']}")
        print(f"üìù Resposta: {response_data['result']}")
        print(f"\nüìö Fontes consultadas ({response_data['num_sources']}):")

        for i, source in enumerate(response_data['source_documents'], 1):
            print(f"  {i}. {source['source']} (P√°gina: {source['page']})")
            if source['content_preview']:
                print(f"     Preview: {source['content_preview']}")
        print("-" * 80)

    def interactive_chat(self):
        """Interface interativa para chat cont√≠nuo."""
        print("=" * 80)
        print("üöÄ CHATBOT RAG - DOCUMENTA√á√ÉO LANGCHAIN")
        print("=" * 80)
        print("Comandos dispon√≠veis:")
        print("  ‚Ä¢ Digite sua pergunta normalmente")
        print("  ‚Ä¢ 'sair' ou 'quit' para encerrar")
        print("  ‚Ä¢ 'limpar' para limpar a tela")
        print("  ‚Ä¢ 'ajuda' para ver este menu")
        print("=" * 80)

        while True:
            try:
                query = input("\nüí¨ Sua pergunta: ").strip()

                if not query:
                    continue

                if query.lower() in ['sair', 'quit', 'exit']:
                    print("üëã Encerrando chatbot. At√© logo!")
                    break

                if query.lower() == 'limpar':
                    os.system('cls' if os.name == 'nt' else 'clear')
                    continue

                if query.lower() == 'ajuda':
                    print("\nüìñ Comandos dispon√≠veis:")
                    print("  ‚Ä¢ Digite sua pergunta normalmente")
                    print("  ‚Ä¢ 'sair' ou 'quit' para encerrar")
                    print("  ‚Ä¢ 'limpar' para limpar a tela")
                    print("  ‚Ä¢ 'ajuda' para ver este menu")
                    continue

                # Processa a pergunta
                response = self.ask_question(query)
                self.display_response(response)

            except KeyboardInterrupt:
                print("\n\nüëã Chatbot interrompido pelo usu√°rio. At√© logo!")
                break
            except Exception as e:
                logger.error(f"Erro inesperado no chat interativo: {e}")
                print(f"‚ùå Erro inesperado: {e}")

    def get_database_info(self) -> Dict:
        """Retorna informa√ß√µes sobre o banco de dados vetorial."""
        try:
            collection = self.vectorstore._collection
            return {
                "total_documents": collection.count(),
                "persist_directory": self.config["persist_directory"],
                "embedding_model": self.config["embedding_model"]
            }
        except Exception as e:
            logger.error(f"Erro ao obter informa√ß√µes do banco: {e}")
            return {"error": str(e)}

def run_examples(chatbot: RAGChatbot):
    """Executa exemplos de perguntas para demonstra√ß√£o."""
    print("\nüîç EXECUTANDO EXEMPLOS DE DEMONSTRA√á√ÉO")
    print("=" * 80)

    example_questions = [
        "O que √© LangChain?",
        "Como usar o WebBaseLoader?",
        "Qual a fun√ß√£o do RecursiveCharacterTextSplitter?",
        "Como configurar um sistema RAG?",
        "Quais s√£o os tipos de chains dispon√≠veis?"
    ]

    for question in example_questions:
        response = chatbot.ask_question(question)
        chatbot.display_response(response)

def main():
    """Fun√ß√£o principal do programa."""
    try:
        # Inicializa o chatbot
        chatbot = RAGChatbot()

        # Mostra informa√ß√µes do banco de dados
        db_info = chatbot.get_database_info()
        if not db_info.get("error"):
            print(f"üìä Banco de dados: {db_info['total_documents']} documentos carregados")

        # Pergunta ao usu√°rio como quer usar o sistema
        print("\nüéØ Como voc√™ gostaria de usar o sistema?")
        print("1. Chat interativo")
        print("2. Executar exemplos de demonstra√ß√£o")
        print("3. Fazer uma pergunta espec√≠fica")

        choice = input("\nEscolha uma op√ß√£o (1-3): ").strip()

        if choice == "1":
            chatbot.interactive_chat()
        elif choice == "2":
            run_examples(chatbot)
        elif choice == "3":
            question = input("Digite sua pergunta: ").strip()
            if question:
                response = chatbot.ask_question(question)
                chatbot.display_response(response)
        else:
            print("Op√ß√£o inv√°lida. Iniciando chat interativo...")
            chatbot.interactive_chat()

    except Exception as e:
        logger.error(f"Erro na execu√ß√£o principal: {e}")
        print(f"‚ùå Erro cr√≠tico: {e}")

if __name__ == "__main__":
    main()
